{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n"
     ]
    }
   ],
   "source": [
    "# import the libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "# import tensorflow_addons as tfa\n",
    "# import efficientnet.tfkeras as efn\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the csv file with the images information\n",
    "data = pd.read_csv('/Users/robsonfeliciano/Downloads/GitHub/TensorflowLite_Image_Classification_Training/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "      <th>label_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_129225211</td>\n",
       "      <td>0000a68812bc7e98c42888dfb1c07da0.jpg</td>\n",
       "      <td>94974f937d4c2433</td>\n",
       "      <td>Paper Bag Victoria Secret</td>\n",
       "      <td>249114794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_3386243561</td>\n",
       "      <td>00039780dfc94d01db8676fe789ecd05.jpg</td>\n",
       "      <td>af3f9460c2838f0f</td>\n",
       "      <td>Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...</td>\n",
       "      <td>2937985045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2288590299</td>\n",
       "      <td>000a190fdd715a2a36faed16e2c65df7.jpg</td>\n",
       "      <td>b94cb00ed3e50f78</td>\n",
       "      <td>Maling TTS Canned Pork Luncheon Meat 397 gr</td>\n",
       "      <td>2395904891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_2406599165</td>\n",
       "      <td>00117e4fc239b1b641ff08340b429633.jpg</td>\n",
       "      <td>8514fc58eafea283</td>\n",
       "      <td>Daster Batik Lengan pendek - Motif Acak / Camp...</td>\n",
       "      <td>4093212188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_3369186413</td>\n",
       "      <td>00136d1cf4edede0203f32f05f660588.jpg</td>\n",
       "      <td>a6f319f924ad708c</td>\n",
       "      <td>Nescafe \\xc3\\x89clair Latte 220ml</td>\n",
       "      <td>3648931069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34245</th>\n",
       "      <td>train_4028265689</td>\n",
       "      <td>fff1c07ceefc2c970a7964cfb81981c5.jpg</td>\n",
       "      <td>e3cd72389f248f21</td>\n",
       "      <td>Masker Bahan Kain Spunbond Non Woven 75 gsm 3 ...</td>\n",
       "      <td>3776555725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34246</th>\n",
       "      <td>train_769054909</td>\n",
       "      <td>fff401691371bdcb382a0d9075dfea6a.jpg</td>\n",
       "      <td>be86851f72e2853c</td>\n",
       "      <td>MamyPoko Pants Royal Soft - S 70 - Popok Celana</td>\n",
       "      <td>2736479533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34247</th>\n",
       "      <td>train_614977732</td>\n",
       "      <td>fff421b78fa7284284724baf249f522e.jpg</td>\n",
       "      <td>ad27f0d08c0fcbf0</td>\n",
       "      <td>KHANZAACC Robot RE101S 1.2mm Subwoofer Bass Me...</td>\n",
       "      <td>4101248785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34248</th>\n",
       "      <td>train_3630949769</td>\n",
       "      <td>fff51b87916dbfb6d0f8faa01bee67b8.jpg</td>\n",
       "      <td>e3b13bd1d896c05c</td>\n",
       "      <td>Kaldu NON MSG HALAL Mama Kamu Ayam Kampung , S...</td>\n",
       "      <td>1663538013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34249</th>\n",
       "      <td>train_1792180725</td>\n",
       "      <td>ffffa0ab2ae542357671e96254fa7167.jpg</td>\n",
       "      <td>af8bc4b2d2cf9083</td>\n",
       "      <td>FLEX TAPE PELAPIS BOCOR / ISOLASI AJAIB / ANTI...</td>\n",
       "      <td>459464107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34250 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             posting_id                                 image  \\\n",
       "0       train_129225211  0000a68812bc7e98c42888dfb1c07da0.jpg   \n",
       "1      train_3386243561  00039780dfc94d01db8676fe789ecd05.jpg   \n",
       "2      train_2288590299  000a190fdd715a2a36faed16e2c65df7.jpg   \n",
       "3      train_2406599165  00117e4fc239b1b641ff08340b429633.jpg   \n",
       "4      train_3369186413  00136d1cf4edede0203f32f05f660588.jpg   \n",
       "...                 ...                                   ...   \n",
       "34245  train_4028265689  fff1c07ceefc2c970a7964cfb81981c5.jpg   \n",
       "34246   train_769054909  fff401691371bdcb382a0d9075dfea6a.jpg   \n",
       "34247   train_614977732  fff421b78fa7284284724baf249f522e.jpg   \n",
       "34248  train_3630949769  fff51b87916dbfb6d0f8faa01bee67b8.jpg   \n",
       "34249  train_1792180725  ffffa0ab2ae542357671e96254fa7167.jpg   \n",
       "\n",
       "            image_phash                                              title  \\\n",
       "0      94974f937d4c2433                          Paper Bag Victoria Secret   \n",
       "1      af3f9460c2838f0f  Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...   \n",
       "2      b94cb00ed3e50f78        Maling TTS Canned Pork Luncheon Meat 397 gr   \n",
       "3      8514fc58eafea283  Daster Batik Lengan pendek - Motif Acak / Camp...   \n",
       "4      a6f319f924ad708c                  Nescafe \\xc3\\x89clair Latte 220ml   \n",
       "...                 ...                                                ...   \n",
       "34245  e3cd72389f248f21  Masker Bahan Kain Spunbond Non Woven 75 gsm 3 ...   \n",
       "34246  be86851f72e2853c    MamyPoko Pants Royal Soft - S 70 - Popok Celana   \n",
       "34247  ad27f0d08c0fcbf0  KHANZAACC Robot RE101S 1.2mm Subwoofer Bass Me...   \n",
       "34248  e3b13bd1d896c05c  Kaldu NON MSG HALAL Mama Kamu Ayam Kampung , S...   \n",
       "34249  af8bc4b2d2cf9083  FLEX TAPE PELAPIS BOCOR / ISOLASI AJAIB / ANTI...   \n",
       "\n",
       "       label_group  \n",
       "0        249114794  \n",
       "1       2937985045  \n",
       "2       2395904891  \n",
       "3       4093212188  \n",
       "4       3648931069  \n",
       "...            ...  \n",
       "34245   3776555725  \n",
       "34246   2736479533  \n",
       "34247   4101248785  \n",
       "34248   1663538013  \n",
       "34249    459464107  \n",
       "\n",
       "[34250 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(subset=['image'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a support column\n",
    "NaN = np.nan\n",
    "data['label'] = NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "# feeding the support column\n",
    "label = 0\n",
    "for i in data['label_group'].unique():\n",
    "    data['label'].loc[data['label_group'] == i] = label\n",
    "    label +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "support = data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32412"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='label_group', ylabel='count'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(data['label_group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = [support.index[i] for i in range(len(support))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1042.0,\n",
       " 252.0,\n",
       " 307.0,\n",
       " 979.0,\n",
       " 48.0,\n",
       " 206.0,\n",
       " 106.0,\n",
       " 283.0,\n",
       " 1071.0,\n",
       " 130.0,\n",
       " 1254.0,\n",
       " 59.0,\n",
       " 943.0,\n",
       " 959.0,\n",
       " 802.0,\n",
       " 529.0,\n",
       " 249.0,\n",
       " 473.0,\n",
       " 3080.0,\n",
       " 550.0,\n",
       " 2281.0,\n",
       " 89.0,\n",
       " 595.0,\n",
       " 2832.0,\n",
       " 2579.0,\n",
       " 2725.0,\n",
       " 589.0,\n",
       " 119.0,\n",
       " 294.0,\n",
       " 1820.0,\n",
       " 538.0,\n",
       " 1007.0,\n",
       " 410.0,\n",
       " 914.0,\n",
       " 77.0,\n",
       " 1876.0,\n",
       " 221.0,\n",
       " 1384.0,\n",
       " 714.0,\n",
       " 174.0,\n",
       " 170.0,\n",
       " 3088.0,\n",
       " 654.0,\n",
       " 3999.0,\n",
       " 2291.0,\n",
       " 1213.0,\n",
       " 1318.0,\n",
       " 414.0,\n",
       " 2801.0,\n",
       " 958.0,\n",
       " 2418.0,\n",
       " 1791.0,\n",
       " 807.0,\n",
       " 167.0,\n",
       " 3294.0,\n",
       " 340.0,\n",
       " 1967.0,\n",
       " 2424.0,\n",
       " 1919.0,\n",
       " 984.0,\n",
       " 4154.0,\n",
       " 441.0,\n",
       " 655.0,\n",
       " 44.0,\n",
       " 168.0,\n",
       " 1533.0,\n",
       " 755.0,\n",
       " 1866.0,\n",
       " 171.0,\n",
       " 1123.0,\n",
       " 229.0,\n",
       " 498.0,\n",
       " 1744.0,\n",
       " 1590.0,\n",
       " 1322.0,\n",
       " 1905.0,\n",
       " 6673.0,\n",
       " 7044.0,\n",
       " 3049.0,\n",
       " 2156.0,\n",
       " 1146.0,\n",
       " 1349.0,\n",
       " 3569.0,\n",
       " 3490.0,\n",
       " 159.0,\n",
       " 2572.0,\n",
       " 6520.0,\n",
       " 899.0,\n",
       " 437.0,\n",
       " 3441.0,\n",
       " 1737.0,\n",
       " 2476.0,\n",
       " 3093.0,\n",
       " 2258.0,\n",
       " 3401.0,\n",
       " 3630.0,\n",
       " 952.0,\n",
       " 1899.0,\n",
       " 1039.0,\n",
       " 1904.0,\n",
       " 1704.0,\n",
       " 164.0,\n",
       " 2175.0,\n",
       " 4555.0,\n",
       " 1048.0,\n",
       " 1328.0,\n",
       " 1795.0,\n",
       " 861.0,\n",
       " 621.0,\n",
       " 1543.0,\n",
       " 915.0,\n",
       " 5577.0,\n",
       " 1695.0,\n",
       " 1873.0,\n",
       " 2292.0,\n",
       " 1789.0,\n",
       " 664.0,\n",
       " 1830.0,\n",
       " 2443.0,\n",
       " 4887.0,\n",
       " 639.0,\n",
       " 1019.0,\n",
       " 1640.0,\n",
       " 1017.0,\n",
       " 2959.0,\n",
       " 1988.0,\n",
       " 1023.0,\n",
       " 1158.0,\n",
       " 3506.0,\n",
       " 4475.0,\n",
       " 7145.0,\n",
       " 817.0,\n",
       " 1536.0,\n",
       " 2055.0,\n",
       " 2198.0,\n",
       " 3004.0,\n",
       " 3035.0,\n",
       " 2641.0,\n",
       " 2357.0,\n",
       " 3260.0,\n",
       " 3568.0,\n",
       " 347.0,\n",
       " 2402.0,\n",
       " 1248.0,\n",
       " 4404.0,\n",
       " 485.0,\n",
       " 836.0,\n",
       " 2698.0,\n",
       " 2502.0,\n",
       " 1715.0,\n",
       " 3602.0,\n",
       " 1203.0,\n",
       " 2564.0,\n",
       " 1428.0,\n",
       " 1455.0,\n",
       " 2565.0,\n",
       " 21.0,\n",
       " 1935.0,\n",
       " 1475.0,\n",
       " 117.0,\n",
       " 4825.0,\n",
       " 3828.0,\n",
       " 523.0,\n",
       " 493.0,\n",
       " 54.0,\n",
       " 3045.0,\n",
       " 1875.0,\n",
       " 471.0,\n",
       " 1788.0,\n",
       " 1886.0,\n",
       " 924.0,\n",
       " 2208.0,\n",
       " 954.0,\n",
       " 2110.0,\n",
       " 445.0,\n",
       " 1921.0,\n",
       " 3974.0,\n",
       " 718.0,\n",
       " 4740.0,\n",
       " 416.0,\n",
       " 1945.0,\n",
       " 1630.0,\n",
       " 3388.0,\n",
       " 1266.0,\n",
       " 2192.0,\n",
       " 1230.0,\n",
       " 5824.0,\n",
       " 5982.0,\n",
       " 665.0,\n",
       " 2395.0,\n",
       " 1300.0,\n",
       " 2449.0,\n",
       " 4999.0,\n",
       " 669.0,\n",
       " 7490.0,\n",
       " 2814.0,\n",
       " 4116.0,\n",
       " 3869.0,\n",
       " 6071.0,\n",
       " 582.0,\n",
       " 726.0,\n",
       " 1512.0,\n",
       " 960.0,\n",
       " 449.0,\n",
       " 5614.0,\n",
       " 101.0,\n",
       " 2017.0,\n",
       " 1548.0,\n",
       " 537.0,\n",
       " 3099.0,\n",
       " 1589.0,\n",
       " 3830.0,\n",
       " 499.0,\n",
       " 3806.0,\n",
       " 3417.0,\n",
       " 1009.0,\n",
       " 6664.0,\n",
       " 2716.0,\n",
       " 2646.0,\n",
       " 359.0,\n",
       " 5092.0,\n",
       " 4060.0,\n",
       " 4137.0,\n",
       " 2600.0,\n",
       " 3478.0,\n",
       " 2553.0,\n",
       " 479.0,\n",
       " 476.0,\n",
       " 5097.0,\n",
       " 3186.0,\n",
       " 1195.0,\n",
       " 791.0,\n",
       " 2634.0,\n",
       " 9720.0,\n",
       " 2494.0,\n",
       " 2749.0,\n",
       " 3333.0,\n",
       " 304.0,\n",
       " 2657.0,\n",
       " 580.0,\n",
       " 3654.0,\n",
       " 2427.0,\n",
       " 2902.0,\n",
       " 2512.0,\n",
       " 2584.0,\n",
       " 7171.0,\n",
       " 3782.0,\n",
       " 386.0,\n",
       " 5266.0,\n",
       " 319.0,\n",
       " 4830.0,\n",
       " 6963.0,\n",
       " 176.0,\n",
       " 2053.0,\n",
       " 2057.0,\n",
       " 4330.0,\n",
       " 1351.0,\n",
       " 7497.0,\n",
       " 1598.0,\n",
       " 1977.0,\n",
       " 4894.0,\n",
       " 2146.0,\n",
       " 1470.0,\n",
       " 1389.0,\n",
       " 1947.0,\n",
       " 1790.0,\n",
       " 6142.0,\n",
       " 4350.0,\n",
       " 118.0,\n",
       " 1319.0,\n",
       " 1915.0,\n",
       " 1520.0,\n",
       " 1754.0,\n",
       " 2027.0,\n",
       " 4864.0,\n",
       " 2038.0,\n",
       " 4608.0,\n",
       " 517.0,\n",
       " 1095.0,\n",
       " 1106.0,\n",
       " 1092.0,\n",
       " 1804.0,\n",
       " 1111.0,\n",
       " 832.0,\n",
       " 519.0,\n",
       " 1448.0,\n",
       " 3213.0,\n",
       " 378.0,\n",
       " 1135.0,\n",
       " 3217.0,\n",
       " 2968.0,\n",
       " 3224.0,\n",
       " 6009.0,\n",
       " 3226.0,\n",
       " 1154.0,\n",
       " 8830.0,\n",
       " 4660.0,\n",
       " 2103.0,\n",
       " 3257.0,\n",
       " 870.0,\n",
       " 2382.0,\n",
       " 1465.0,\n",
       " 998.0,\n",
       " 3944.0,\n",
       " 1571.0,\n",
       " 409.0,\n",
       " 5663.0,\n",
       " 1970.0,\n",
       " 4505.0,\n",
       " 989.0,\n",
       " 2756.0,\n",
       " 1943.0,\n",
       " 5168.0,\n",
       " 969.0,\n",
       " 114.0,\n",
       " 7552.0,\n",
       " 4869.0,\n",
       " 3848.0,\n",
       " 7526.0,\n",
       " 486.0,\n",
       " 5572.0,\n",
       " 1480.0,\n",
       " 400.0,\n",
       " 2838.0,\n",
       " 3979.0,\n",
       " 3072.0,\n",
       " 151.0,\n",
       " 152.0,\n",
       " 6040.0,\n",
       " 6239.0,\n",
       " 2104.0,\n",
       " 1818.0,\n",
       " 1468.0,\n",
       " 6553.0,\n",
       " 3736.0,\n",
       " 4544.0,\n",
       " 4713.0,\n",
       " 2373.0,\n",
       " 1277.0,\n",
       " 3385.0,\n",
       " 1358.0,\n",
       " 14.0,\n",
       " 1758.0,\n",
       " 2513.0,\n",
       " 8235.0,\n",
       " 722.0,\n",
       " 1656.0,\n",
       " 3649.0,\n",
       " 2485.0,\n",
       " 4153.0,\n",
       " 218.0,\n",
       " 333.0,\n",
       " 6626.0,\n",
       " 1366.0,\n",
       " 5382.0,\n",
       " 4197.0,\n",
       " 4198.0,\n",
       " 5385.0,\n",
       " 5397.0,\n",
       " 7162.0,\n",
       " 1698.0,\n",
       " 3386.0,\n",
       " 7316.0,\n",
       " 42.0,\n",
       " 4143.0,\n",
       " 3358.0,\n",
       " 7614.0,\n",
       " 757.0,\n",
       " 6150.0,\n",
       " 6606.0,\n",
       " 1624.0,\n",
       " 947.0,\n",
       " 5370.0,\n",
       " 482.0,\n",
       " 3499.0,\n",
       " 917.0,\n",
       " 3474.0,\n",
       " 946.0,\n",
       " 6.0,\n",
       " 4759.0,\n",
       " 686.0,\n",
       " 4765.0,\n",
       " 3451.0,\n",
       " 637.0,\n",
       " 3053.0,\n",
       " 108.0,\n",
       " 1565.0,\n",
       " 3047.0,\n",
       " 916.0,\n",
       " 1893.0,\n",
       " 5190.0,\n",
       " 3484.0,\n",
       " 3030.0,\n",
       " 6905.0,\n",
       " 1551.0,\n",
       " 3043.0,\n",
       " 8420.0,\n",
       " 4554.0,\n",
       " 616.0,\n",
       " 1869.0,\n",
       " 1858.0,\n",
       " 1696.0,\n",
       " 3040.0,\n",
       " 3450.0,\n",
       " 4672.0,\n",
       " 6206.0,\n",
       " 4680.0,\n",
       " 733.0,\n",
       " 9353.0,\n",
       " 1603.0,\n",
       " 6618.0,\n",
       " 3348.0,\n",
       " 1798.0,\n",
       " 58.0,\n",
       " 833.0,\n",
       " 5230.0,\n",
       " 3430.0,\n",
       " 1610.0,\n",
       " 772.0,\n",
       " 3223.0,\n",
       " 5458.0,\n",
       " 5468.0,\n",
       " 3277.0,\n",
       " 53.0,\n",
       " 4808.0,\n",
       " 5421.0,\n",
       " 576.0,\n",
       " 860.0,\n",
       " 1761.0,\n",
       " 3426.0,\n",
       " 707.0,\n",
       " 23.0,\n",
       " 4609.0,\n",
       " 5401.0,\n",
       " 72.0,\n",
       " 592.0,\n",
       " 3636.0,\n",
       " 1741.0,\n",
       " 1742.0,\n",
       " 502.0,\n",
       " 3117.0,\n",
       " 876.0,\n",
       " 3130.0,\n",
       " 5532.0,\n",
       " 510.0,\n",
       " 6216.0,\n",
       " 530.0,\n",
       " 3901.0,\n",
       " 1233.0,\n",
       " 1239.0,\n",
       " 4409.0,\n",
       " 4089.0,\n",
       " 5701.0,\n",
       " 2011.0,\n",
       " 3989.0,\n",
       " 1354.0,\n",
       " 1348.0,\n",
       " 6769.0,\n",
       " 156.0,\n",
       " 8234.0,\n",
       " 5818.0,\n",
       " 310.0,\n",
       " 2378.0,\n",
       " 8795.0,\n",
       " 183.0,\n",
       " 2612.0,\n",
       " 1378.0,\n",
       " 2744.0,\n",
       " 1362.0,\n",
       " 2186.0,\n",
       " 1229.0,\n",
       " 4032.0,\n",
       " 1199.0,\n",
       " 172.0,\n",
       " 1103.0,\n",
       " 2171.0,\n",
       " 5836.0,\n",
       " 4416.0,\n",
       " 2659.0,\n",
       " 7639.0,\n",
       " 4054.0,\n",
       " 4487.0,\n",
       " 148.0,\n",
       " 2541.0,\n",
       " 2923.0,\n",
       " 2943.0,\n",
       " 2124.0,\n",
       " 5171.0,\n",
       " 2302.0,\n",
       " 1939.0,\n",
       " 1511.0,\n",
       " 4393.0,\n",
       " 8730.0,\n",
       " 7394.0,\n",
       " 1413.0,\n",
       " 962.0,\n",
       " 320.0,\n",
       " 2547.0,\n",
       " 440.0,\n",
       " 198.0,\n",
       " 5799.0,\n",
       " 215.0,\n",
       " 2583.0,\n",
       " 6505.0,\n",
       " 4115.0,\n",
       " 331.0,\n",
       " 6426.0,\n",
       " 5884.0,\n",
       " 7265.0,\n",
       " 2540.0,\n",
       " 2269.0,\n",
       " 2539.0,\n",
       " 739.0,\n",
       " 1636.0,\n",
       " 3406.0,\n",
       " 5440.0,\n",
       " 1398.0,\n",
       " 1380.0,\n",
       " 1374.0,\n",
       " 7996.0,\n",
       " 1760.0,\n",
       " 2129.0,\n",
       " 6522.0,\n",
       " 2176.0,\n",
       " 2319.0,\n",
       " 1711.0,\n",
       " 3482.0,\n",
       " 673.0,\n",
       " 672.0,\n",
       " 2231.0,\n",
       " 670.0,\n",
       " 1667.0,\n",
       " 2318.0,\n",
       " 1740.0,\n",
       " 661.0,\n",
       " 2238.0,\n",
       " 2254.0,\n",
       " 1672.0,\n",
       " 2290.0,\n",
       " 2282.0,\n",
       " 7363.0,\n",
       " 3479.0,\n",
       " 1718.0,\n",
       " 7694.0,\n",
       " 1339.0,\n",
       " 2481.0,\n",
       " 1367.0,\n",
       " 1735.0,\n",
       " 3324.0,\n",
       " 2433.0,\n",
       " 1360.0,\n",
       " 8011.0,\n",
       " 2425.0,\n",
       " 697.0,\n",
       " 690.0,\n",
       " 2215.0,\n",
       " 2219.0,\n",
       " 5872.0,\n",
       " 2392.0,\n",
       " 1730.0,\n",
       " 2549.0,\n",
       " 1616.0,\n",
       " 6601.0,\n",
       " 2843.0,\n",
       " 1497.0,\n",
       " 1850.0,\n",
       " 1012.0,\n",
       " 6540.0,\n",
       " 1022.0,\n",
       " 2858.0,\n",
       " 2855.0,\n",
       " 7569.0,\n",
       " 1462.0,\n",
       " 895.0,\n",
       " 2827.0,\n",
       " 1835.0,\n",
       " 1823.0,\n",
       " 1585.0,\n",
       " 6552.0,\n",
       " 1593.0,\n",
       " 1949.0,\n",
       " 1006.0,\n",
       " 911.0,\n",
       " 1556.0,\n",
       " 1912.0,\n",
       " 1901.0,\n",
       " 950.0,\n",
       " 1930.0,\n",
       " 1534.0,\n",
       " 2992.0,\n",
       " 937.0,\n",
       " 2997.0,\n",
       " 1941.0,\n",
       " 2945.0,\n",
       " 2942.0,\n",
       " 7543.0,\n",
       " 988.0,\n",
       " 2911.0,\n",
       " 995.0,\n",
       " 7280.0,\n",
       " 3115.0,\n",
       " 3318.0,\n",
       " 7199.0,\n",
       " 820.0,\n",
       " 2077.0,\n",
       " 6001.0,\n",
       " 2589.0,\n",
       " 3249.0,\n",
       " 7311.0,\n",
       " 800.0,\n",
       " 1415.0,\n",
       " 1072.0,\n",
       " 6148.0,\n",
       " 3284.0,\n",
       " 785.0,\n",
       " 3296.0,\n",
       " 3299.0,\n",
       " 5459.0,\n",
       " 2117.0,\n",
       " 821.0,\n",
       " 2608.0,\n",
       " 828.0,\n",
       " 1437.0,\n",
       " 6468.0,\n",
       " 3134.0,\n",
       " 1077.0,\n",
       " 2707.0,\n",
       " 1806.0,\n",
       " 3152.0,\n",
       " 5513.0,\n",
       " 2670.0,\n",
       " 2049.0,\n",
       " 2656.0,\n",
       " 6014.0,\n",
       " 2637.0,\n",
       " 1129.0,\n",
       " 1133.0,\n",
       " 1136.0,\n",
       " 1305.0,\n",
       " 839.0,\n",
       " 4080.0,\n",
       " 4123.0,\n",
       " 483.0,\n",
       " 481.0,\n",
       " 4430.0,\n",
       " 6800.0,\n",
       " 5091.0,\n",
       " 343.0,\n",
       " 4471.0,\n",
       " 467.0,\n",
       " 155.0,\n",
       " 3866.0,\n",
       " 8333.0,\n",
       " 4254.0,\n",
       " 353.0,\n",
       " 570.0,\n",
       " 4517.0,\n",
       " 4074.0,\n",
       " 3873.0,\n",
       " 8093.0,\n",
       " 5281.0,\n",
       " 126.0,\n",
       " 3660.0,\n",
       " 4069.0,\n",
       " 3659.0,\n",
       " 4870.0,\n",
       " 3877.0,\n",
       " 6692.0,\n",
       " 112.0,\n",
       " 5183.0,\n",
       " 4851.0,\n",
       " 560.0,\n",
       " 4931.0,\n",
       " 5179.0,\n",
       " 188.0,\n",
       " 4252.0,\n",
       " 8129.0,\n",
       " 4299.0,\n",
       " 275.0,\n",
       " 5236.0,\n",
       " 277.0,\n",
       " 280.0,\n",
       " 4306.0,\n",
       " 8762.0,\n",
       " 3812.0,\n",
       " 6849.0,\n",
       " 4981.0,\n",
       " 4324.0,\n",
       " 5040.0,\n",
       " 219.0,\n",
       " 4357.0,\n",
       " 4176.0,\n",
       " 5045.0,\n",
       " 297.0,\n",
       " 5204.0,\n",
       " 546.0,\n",
       " 4372.0,\n",
       " 302.0,\n",
       " 5201.0,\n",
       " 548.0,\n",
       " 195.0,\n",
       " 4933.0,\n",
       " 189.0,\n",
       " 4140.0,\n",
       " 6685.0,\n",
       " 259.0,\n",
       " 436.0,\n",
       " 5119.0,\n",
       " 381.0,\n",
       " 3550.0,\n",
       " 4011.0,\n",
       " 384.0,\n",
       " 424.0,\n",
       " 8171.0,\n",
       " 4790.0,\n",
       " 4654.0,\n",
       " 6756.0,\n",
       " 4710.0,\n",
       " 399.0,\n",
       " 5162.0,\n",
       " 85.0,\n",
       " 8070.0,\n",
       " 4703.0,\n",
       " 632.0,\n",
       " 5344.0,\n",
       " 3958.0,\n",
       " 6760.0,\n",
       " 627.0,\n",
       " 63.0,\n",
       " 4690.0,\n",
       " 3968.0,\n",
       " 88.0,\n",
       " 4684.0,\n",
       " 3613.0,\n",
       " 624.0,\n",
       " 3917.0,\n",
       " 8777.0,\n",
       " 8238.0,\n",
       " 290.0,\n",
       " 1216.0,\n",
       " 5748.0,\n",
       " 296.0,\n",
       " 2505.0,\n",
       " 2845.0,\n",
       " 6405.0,\n",
       " 2840.0,\n",
       " 4166.0,\n",
       " 5053.0,\n",
       " 1194.0,\n",
       " 2527.0,\n",
       " 7732.0,\n",
       " 5046.0,\n",
       " 6822.0,\n",
       " 2462.0,\n",
       " 2846.0,\n",
       " 3930.0,\n",
       " 9821.0,\n",
       " 7686.0,\n",
       " 6377.0,\n",
       " 2377.0,\n",
       " 5878.0,\n",
       " 2394.0,\n",
       " 272.0,\n",
       " 2400.0,\n",
       " 7343.0,\n",
       " 4215.0,\n",
       " 1246.0,\n",
       " 7700.0,\n",
       " 2414.0,\n",
       " 2415.0,\n",
       " 2417.0,\n",
       " 3938.0,\n",
       " 5655.0,\n",
       " 5658.0,\n",
       " 278.0,\n",
       " 5032.0,\n",
       " 407.0,\n",
       " 5667.0,\n",
       " 2861.0,\n",
       " 8898.0,\n",
       " 1224.0,\n",
       " 5853.0,\n",
       " 5820.0,\n",
       " 10421.0,\n",
       " 309.0,\n",
       " 2644.0,\n",
       " 1137.0,\n",
       " 1066.0,\n",
       " 2627.0,\n",
       " 2631.0,\n",
       " 2752.0,\n",
       " 354.0,\n",
       " 2741.0,\n",
       " 5731.0,\n",
       " 2727.0,\n",
       " 2639.0,\n",
       " 2640.0,\n",
       " 1087.0,\n",
       " 2714.0,\n",
       " 6445.0,\n",
       " 3982.0,\n",
       " 7768.0,\n",
       " 2703.0,\n",
       " 5106.0,\n",
       " 7300.0,\n",
       " 1094.0,\n",
       " 2658.0,\n",
       " 7298.0,\n",
       " 5111.0,\n",
       " 8860.0,\n",
       " 2673.0,\n",
       " 8867.0,\n",
       " 4037.0,\n",
       " 5754.0,\n",
       " 2619.0,\n",
       " 5784.0,\n",
       " 2611.0,\n",
       " 1144.0,\n",
       " 7050.0,\n",
       " 1184.0,\n",
       " 2696.0,\n",
       " 8220.0,\n",
       " 3983.0,\n",
       " 2559.0,\n",
       " 2821.0,\n",
       " 6777.0,\n",
       " 2809.0,\n",
       " 3988.0,\n",
       " 2804.0,\n",
       " 6802.0,\n",
       " 5803.0,\n",
       " 332.0,\n",
       " 336.0,\n",
       " 5085.0,\n",
       " 5349.0,\n",
       " 6432.0,\n",
       " 5698.0,\n",
       " 2786.0,\n",
       " 2773.0,\n",
       " 5711.0,\n",
       " 1064.0,\n",
       " 2601.0,\n",
       " 1150.0,\n",
       " 2603.0,\n",
       " 4094.0,\n",
       " 6430.0,\n",
       " 2230.0,\n",
       " 1285.0,\n",
       " 8524.0,\n",
       " 1891.0,\n",
       " 6093.0,\n",
       " 1888.0,\n",
       " 1544.0,\n",
       " 1879.0,\n",
       " 1877.0,\n",
       " 1550.0,\n",
       " 1871.0,\n",
       " 1822.0,\n",
       " 1864.0,\n",
       " 6248.0,\n",
       " 6108.0,\n",
       " 7450.0,\n",
       " 4611.0,\n",
       " 79.0,\n",
       " 78.0,\n",
       " 4564.0,\n",
       " 110.0,\n",
       " 8549.0,\n",
       " 1530.0,\n",
       " 1948.0,\n",
       " 1502.0,\n",
       " 137.0,\n",
       " 4885.0,\n",
       " 1938.0,\n",
       " 4522.0,\n",
       " 1932.0,\n",
       " 6080.0,\n",
       " 1922.0,\n",
       " 4534.0,\n",
       " 4871.0,\n",
       " 4545.0,\n",
       " 1909.0,\n",
       " 1527.0,\n",
       " 4868.0,\n",
       " 1582.0,\n",
       " 7522.0,\n",
       " 1951.0,\n",
       " 6167.0,\n",
       " 4702.0,\n",
       " 31.0,\n",
       " 6926.0,\n",
       " 6209.0,\n",
       " 6208.0,\n",
       " 8438.0,\n",
       " 4730.0,\n",
       " 6202.0,\n",
       " 1819.0,\n",
       " 18.0,\n",
       " 6956.0,\n",
       " 6955.0,\n",
       " 4770.0,\n",
       " 6182.0,\n",
       " 1674.0,\n",
       " 1688.0,\n",
       " 6155.0,\n",
       " 6217.0,\n",
       " 7504.0,\n",
       " 6219.0,\n",
       " 73.0,\n",
       " 1815.0,\n",
       " 1595.0,\n",
       " 6132.0,\n",
       " 8494.0,\n",
       " 1600.0,\n",
       " 1799.0,\n",
       " 61.0,\n",
       " 1608.0,\n",
       " 4658.0,\n",
       " 6226.0,\n",
       " 1787.0,\n",
       " 4809.0,\n",
       " 1764.0,\n",
       " 1625.0,\n",
       " 6886.0,\n",
       " 6063.0,\n",
       " 5908.0,\n",
       " 1365.0,\n",
       " 2894.0,\n",
       " 2222.0,\n",
       " 4311.0,\n",
       " 234.0,\n",
       " 2202.0,\n",
       " 4321.0,\n",
       " 4976.0,\n",
       " 6856.0,\n",
       " 204.0,\n",
       " 213.0,\n",
       " 2168.0,\n",
       " 7383.0,\n",
       " 1382.0,\n",
       " 1383.0,\n",
       " 5965.0,\n",
       " 5966.0,\n",
       " 1333.0,\n",
       " 2244.0,\n",
       " 2248.0,\n",
       " 9851.0,\n",
       " 257.0,\n",
       " 2286.0,\n",
       " 2285.0,\n",
       " 5912.0,\n",
       " 1302.0,\n",
       " 5005.0,\n",
       " 4276.0,\n",
       " 1309.0,\n",
       " 7361.0,\n",
       " 248.0,\n",
       " 1315.0,\n",
       " 247.0,\n",
       " 1320.0,\n",
       " 2266.0,\n",
       " 4294.0,\n",
       " 7015.0,\n",
       " 2144.0,\n",
       " 1980.0,\n",
       " 2020.0,\n",
       " 1446.0,\n",
       " 4439.0,\n",
       " 1451.0,\n",
       " 7582.0,\n",
       " 6294.0,\n",
       " 1464.0,\n",
       " 8606.0,\n",
       " 4909.0,\n",
       " 2140.0,\n",
       " 1471.0,\n",
       " 2002.0,\n",
       " 6051.0,\n",
       " 149.0,\n",
       " 1987.0,\n",
       " 1985.0,\n",
       " 6057.0,\n",
       " 177.0,\n",
       " 2059.0,\n",
       " 4424.0,\n",
       " 1439.0,\n",
       " 2126.0,\n",
       " 7391.0,\n",
       " 2125.0,\n",
       " 2121.0,\n",
       " 1408.0,\n",
       " 2119.0,\n",
       " 4383.0,\n",
       " 4392.0,\n",
       " 2100.0,\n",
       " 1423.0,\n",
       " 2080.0,\n",
       " 10292.0,\n",
       " 2075.0,\n",
       " 1436.0,\n",
       " ...]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['label'].isin(final)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "      <th>label_group</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_129225211</td>\n",
       "      <td>0000a68812bc7e98c42888dfb1c07da0.jpg</td>\n",
       "      <td>94974f937d4c2433</td>\n",
       "      <td>Paper Bag Victoria Secret</td>\n",
       "      <td>249114794</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_3386243561</td>\n",
       "      <td>00039780dfc94d01db8676fe789ecd05.jpg</td>\n",
       "      <td>af3f9460c2838f0f</td>\n",
       "      <td>Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...</td>\n",
       "      <td>2937985045</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2288590299</td>\n",
       "      <td>000a190fdd715a2a36faed16e2c65df7.jpg</td>\n",
       "      <td>b94cb00ed3e50f78</td>\n",
       "      <td>Maling TTS Canned Pork Luncheon Meat 397 gr</td>\n",
       "      <td>2395904891</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_2406599165</td>\n",
       "      <td>00117e4fc239b1b641ff08340b429633.jpg</td>\n",
       "      <td>8514fc58eafea283</td>\n",
       "      <td>Daster Batik Lengan pendek - Motif Acak / Camp...</td>\n",
       "      <td>4093212188</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_3369186413</td>\n",
       "      <td>00136d1cf4edede0203f32f05f660588.jpg</td>\n",
       "      <td>a6f319f924ad708c</td>\n",
       "      <td>Nescafe \\xc3\\x89clair Latte 220ml</td>\n",
       "      <td>3648931069</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34245</th>\n",
       "      <td>train_4028265689</td>\n",
       "      <td>fff1c07ceefc2c970a7964cfb81981c5.jpg</td>\n",
       "      <td>e3cd72389f248f21</td>\n",
       "      <td>Masker Bahan Kain Spunbond Non Woven 75 gsm 3 ...</td>\n",
       "      <td>3776555725</td>\n",
       "      <td>10869.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34246</th>\n",
       "      <td>train_769054909</td>\n",
       "      <td>fff401691371bdcb382a0d9075dfea6a.jpg</td>\n",
       "      <td>be86851f72e2853c</td>\n",
       "      <td>MamyPoko Pants Royal Soft - S 70 - Popok Celana</td>\n",
       "      <td>2736479533</td>\n",
       "      <td>5713.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34247</th>\n",
       "      <td>train_614977732</td>\n",
       "      <td>fff421b78fa7284284724baf249f522e.jpg</td>\n",
       "      <td>ad27f0d08c0fcbf0</td>\n",
       "      <td>KHANZAACC Robot RE101S 1.2mm Subwoofer Bass Me...</td>\n",
       "      <td>4101248785</td>\n",
       "      <td>114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34248</th>\n",
       "      <td>train_3630949769</td>\n",
       "      <td>fff51b87916dbfb6d0f8faa01bee67b8.jpg</td>\n",
       "      <td>e3b13bd1d896c05c</td>\n",
       "      <td>Kaldu NON MSG HALAL Mama Kamu Ayam Kampung , S...</td>\n",
       "      <td>1663538013</td>\n",
       "      <td>7935.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34249</th>\n",
       "      <td>train_1792180725</td>\n",
       "      <td>ffffa0ab2ae542357671e96254fa7167.jpg</td>\n",
       "      <td>af8bc4b2d2cf9083</td>\n",
       "      <td>FLEX TAPE PELAPIS BOCOR / ISOLASI AJAIB / ANTI...</td>\n",
       "      <td>459464107</td>\n",
       "      <td>11005.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32412 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             posting_id                                 image  \\\n",
       "0       train_129225211  0000a68812bc7e98c42888dfb1c07da0.jpg   \n",
       "1      train_3386243561  00039780dfc94d01db8676fe789ecd05.jpg   \n",
       "2      train_2288590299  000a190fdd715a2a36faed16e2c65df7.jpg   \n",
       "3      train_2406599165  00117e4fc239b1b641ff08340b429633.jpg   \n",
       "4      train_3369186413  00136d1cf4edede0203f32f05f660588.jpg   \n",
       "...                 ...                                   ...   \n",
       "34245  train_4028265689  fff1c07ceefc2c970a7964cfb81981c5.jpg   \n",
       "34246   train_769054909  fff401691371bdcb382a0d9075dfea6a.jpg   \n",
       "34247   train_614977732  fff421b78fa7284284724baf249f522e.jpg   \n",
       "34248  train_3630949769  fff51b87916dbfb6d0f8faa01bee67b8.jpg   \n",
       "34249  train_1792180725  ffffa0ab2ae542357671e96254fa7167.jpg   \n",
       "\n",
       "            image_phash                                              title  \\\n",
       "0      94974f937d4c2433                          Paper Bag Victoria Secret   \n",
       "1      af3f9460c2838f0f  Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...   \n",
       "2      b94cb00ed3e50f78        Maling TTS Canned Pork Luncheon Meat 397 gr   \n",
       "3      8514fc58eafea283  Daster Batik Lengan pendek - Motif Acak / Camp...   \n",
       "4      a6f319f924ad708c                  Nescafe \\xc3\\x89clair Latte 220ml   \n",
       "...                 ...                                                ...   \n",
       "34245  e3cd72389f248f21  Masker Bahan Kain Spunbond Non Woven 75 gsm 3 ...   \n",
       "34246  be86851f72e2853c    MamyPoko Pants Royal Soft - S 70 - Popok Celana   \n",
       "34247  ad27f0d08c0fcbf0  KHANZAACC Robot RE101S 1.2mm Subwoofer Bass Me...   \n",
       "34248  e3b13bd1d896c05c  Kaldu NON MSG HALAL Mama Kamu Ayam Kampung , S...   \n",
       "34249  af8bc4b2d2cf9083  FLEX TAPE PELAPIS BOCOR / ISOLASI AJAIB / ANTI...   \n",
       "\n",
       "       label_group    label  \n",
       "0        249114794      0.0  \n",
       "1       2937985045      1.0  \n",
       "2       2395904891      2.0  \n",
       "3       4093212188      3.0  \n",
       "4       3648931069      4.0  \n",
       "...            ...      ...  \n",
       "34245   3776555725  10869.0  \n",
       "34246   2736479533   5713.0  \n",
       "34247   4101248785    114.0  \n",
       "34248   1663538013   7935.0  \n",
       "34249    459464107  11005.0  \n",
       "\n",
       "[32412 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image folder address\n",
    "data_path = '/Users/robsonfeliciano/Downloads/GitHub/TensorflowLite_Image_Classification_Training/shopee-product-matching'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 200\n",
    "img_width = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32412 files belonging to 1 classes.\n",
      "Using 25930 files for training.\n",
      "Metal device set to: Apple M1 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-27 16:11:22.080382: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-12-27 16:11:22.080560: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_path,\n",
    "  labels = list(data['label']),\n",
    "  label_mode = 'int',\n",
    "  validation_split=0.20,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32412 files belonging to 1 classes.\n",
      "Using 6482 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_path,\n",
    "  labels = list(data['label']),\n",
    "  label_mode = 'int',\n",
    "  validation_split=0.20,\n",
    "  subset=\"validation\",\n",
    "  seed=143,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTO)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "  [\n",
    "    layers.experimental.preprocessing.RandomFlip(\"horizontal\", \n",
    "                                                 input_shape=(img_height, \n",
    "                                                              img_width,\n",
    "                                                              3)),\n",
    "    layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "    layers.experimental.preprocessing.RandomZoom(0.1),\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(list(data['label'].unique()))\n",
    "\n",
    "model = Sequential([\n",
    "    data_augmentation,\n",
    "    layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "    layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_applications.imagenet_utils import _obtain_input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.applications' has no attribute '_help_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3j/8ntx2dl50txdncnzs2t83lqc0000gn/T/ipykernel_27122/3728368802.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_help_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.applications' has no attribute '_help_'"
     ]
    }
   ],
   "source": [
    "applications._help_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "class SiameseModel(Model):\n",
    "    \"\"\"The Siamese Network model with a custom training and testing loops.\n",
    "\n",
    "    Computes the triplet loss using the three embeddings produced by the\n",
    "    Siamese Network.\n",
    "\n",
    "    The triplet loss is defined as:\n",
    "       L(A, P, N) = max(â€–f(A) - f(P)â€–Â² - â€–f(A) - f(N)â€–Â² + margin, 0)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, siamese_network, margin=0.5):\n",
    "        super(SiameseModel, self).__init__()\n",
    "        self.siamese_network = siamese_network\n",
    "        self.margin = margin\n",
    "        self.loss_tracker = metrics.Mean(name=\"loss\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.siamese_network(inputs)\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # GradientTape is a context manager that records every operation that\n",
    "        # you do inside. We are using it here to compute the loss so we can get\n",
    "        # the gradients and apply them using the optimizer specified in\n",
    "        # `compile()`.\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = self._compute_loss(data)\n",
    "\n",
    "        # Storing the gradients of the loss function with respect to the\n",
    "        # weights/parameters.\n",
    "        gradients = tape.gradient(loss, self.siamese_network.trainable_weights)\n",
    "\n",
    "        # Applying the gradients on the model using the specified optimizer\n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(gradients, self.siamese_network.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Let's update and return the training loss metric.\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {\"loss\": self.loss_tracker.result()}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        loss = self._compute_loss(data)\n",
    "\n",
    "        # Let's update and return the loss metric.\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {\"loss\": self.loss_tracker.result()}\n",
    "\n",
    "    def _compute_loss(self, data):\n",
    "        # The output of the network is a tuple containing the distances\n",
    "        # between the anchor and the positive example, and the anchor and\n",
    "        # the negative example.\n",
    "        ap_distance, an_distance = self.siamese_network(data)\n",
    "\n",
    "        # Computing the Triplet Loss by subtracting both distances and\n",
    "        # making sure we don't get a negative value.\n",
    "        loss = ap_distance - an_distance\n",
    "        loss = tf.maximum(loss + self.margin, 0.0)\n",
    "        return loss\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        # We need to list our metrics here so the `reset_states()` can be\n",
    "        # called automatically.\n",
    "        return [self.loss_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'resnet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3j/8ntx2dl50txdncnzs2t83lqc0000gn/T/ipykernel_27122/1312674669.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mresnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresnet_sd_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m model = resnet_sd_model(img_shape = (180,180), img_channels = 3, \n\u001b[1;32m      4\u001b[0m                             layers = 152, nb_classes = num_classes, verbose = True)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'resnet'"
     ]
    }
   ],
   "source": [
    "from resnet import resnet_sd_model\n",
    "\n",
    "model = resnet_sd_model(img_shape = (180,180), img_channels = 3, \n",
    "                            layers = 152, nb_classes = num_classes, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_callbacks():\n",
    "    \n",
    "    cpk_path = './best_model.h5'\n",
    "    \n",
    "    reducelr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        factor=0.1,\n",
    "        patience=3,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=cpk_path,\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        save_best_only=True,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    earlystop = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        patience=10, \n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    callbacks = [checkpoint, reducelr, earlystop]         \n",
    "    \n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_distances(embeddings):\n",
    "    dot_product = tf.linalg.matmul(embeddings, tf.transpose(embeddings))\n",
    "    square_norm = tf.linalg.diag_part(dot_product)\n",
    "    distances = tf.expand_dims(square_norm, 1) - 2.0 * dot_product + tf.expand_dims(square_norm, 0)\n",
    "    distances = tf.math.maximum(distances, 0.0)\n",
    "\n",
    "    mask = tf.cast(tf.equal(distances, 0.0),tf.float32)\n",
    "    distances = distances + mask * 1e-16\n",
    "    distances = tf.math.sqrt(distances)\n",
    "    distances = distances * (1.0 - mask)\n",
    "\n",
    "    return distances\n",
    "\n",
    "def get_anchor_positive_triplet_mask(labels):\n",
    "    indices_equal = tf.cast(tf.eye(tf.shape(labels)[0]), tf.bool)\n",
    "    indices_not_equal = tf.math.logical_not(indices_equal)\n",
    "\n",
    "    labels_equal = tf.math.equal(tf.expand_dims(labels, 0), tf.expand_dims(labels, 1))\n",
    "    mask = tf.math.logical_and(indices_not_equal, labels_equal)\n",
    "\n",
    "    return mask\n",
    "\n",
    "def get_anchor_negative_triplet_mask(labels):\n",
    "    labels_equal = tf.math.equal(tf.expand_dims(labels, 0), tf.expand_dims(labels, 1))\n",
    "    mask = tf.math.logical_not(labels_equal)\n",
    "\n",
    "    return mask\n",
    "\n",
    "def get_triplet_mask(labels):\n",
    "    indices_equal = tf.cast(tf.eye(tf.shape(labels)[0]), tf.bool)\n",
    "    indices_not_equal = tf.math.logical_not(indices_equal)\n",
    "    i_not_equal_j = tf.expand_dims(indices_not_equal, 2)\n",
    "    i_not_equal_k = tf.expand_dims(indices_not_equal, 1)\n",
    "    j_not_equal_k = tf.expand_dims(indices_not_equal, 0)\n",
    "\n",
    "    distinct_indices = tf.math.logical_and(tf.math.logical_and(i_not_equal_j, i_not_equal_k), j_not_equal_k)\n",
    "\n",
    "\n",
    "    label_equal = tf.math.equal(tf.expand_dims(labels, 0), tf.expand_dims(labels, 1))\n",
    "    i_equal_j = tf.expand_dims(label_equal, 2)\n",
    "    i_equal_k = tf.expand_dims(label_equal, 1)\n",
    "\n",
    "    valid_labels = tf.math.logical_and(i_equal_j, tf.logical_not(i_equal_k))\n",
    "\n",
    "    mask = tf.math.logical_and(distinct_indices, valid_labels)\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "class TripletLossFn(tf.keras.losses.Loss):\n",
    "    def __init__(self,margin=1.0,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.margin = margin\n",
    "  \n",
    "    def call(self,y_true,y_pred):\n",
    "\n",
    "        labels = tf.convert_to_tensor(y_true)\n",
    "        labels = tf.squeeze(labels,axis=-1)\n",
    "        embeddings = tf.convert_to_tensor(y_pred)\n",
    "\n",
    "        pairwise_dist = pairwise_distances(embeddings)\n",
    "\n",
    "        mask_anchor_positive = get_anchor_positive_triplet_mask(labels)\n",
    "        mask_anchor_positive = tf.cast(mask_anchor_positive,tf.float32)\n",
    "\n",
    "        anchor_positive_dist = tf.math.multiply(mask_anchor_positive, pairwise_dist)\n",
    "\n",
    "        hardest_positive_dist = tf.math.reduce_max(anchor_positive_dist, axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "        mask_anchor_negative = get_anchor_negative_triplet_mask(labels)\n",
    "        mask_anchor_negative = tf.cast(mask_anchor_negative,tf.float32)\n",
    "\n",
    "        max_anchor_negative_dist = tf.math.reduce_max(pairwise_dist, axis=1, keepdims=True)\n",
    "        anchor_negative_dist = pairwise_dist + max_anchor_negative_dist * (1.0 - mask_anchor_negative)\n",
    "\n",
    "\n",
    "        hardest_negative_dist = tf.math.reduce_min(anchor_negative_dist, axis=1, keepdims=True)\n",
    "    \n",
    "\n",
    "        triplet_loss = tf.math.maximum(hardest_positive_dist - hardest_negative_dist + self.margin, 0.0)\n",
    "\n",
    "        triplet_loss = tf.math.reduce_mean(triplet_loss)\n",
    "\n",
    "        return triplet_loss\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config,\"margin\":self.margin}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (457176115.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/3j/8ntx2dl50txdncnzs2t83lqc0000gn/T/ipykernel_27122/457176115.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    logits_w_temp = tf.divide(, temp)  # logits after dividing with T\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "logits_w_temp = tf.divide(, temp)  # logits after dividing with T\n",
    " \n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=logits_w_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential (Sequential)      (None, 200, 200, 3)       0         \n",
      "_________________________________________________________________\n",
      "rescaling (Rescaling)        (None, 200, 200, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 200, 200, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 100, 100, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 100, 100, 32)      4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 50, 50, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 50, 50, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 25, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 40000)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               5120128   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 11011)             1420419   \n",
      "=================================================================\n",
      "Total params: 6,564,131\n",
      "Trainable params: 6,564,131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:855 train_function  *\n        return step_function(self, iterator)\n    /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:845 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:838 run_step  **\n        outputs = model.train_step(data)\n    /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:799 train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:530 minimize\n        return self.apply_gradients(grads_and_vars, name=name)\n    /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:630 apply_gradients\n        grads_and_vars = optimizer_utils.filter_empty_gradients(grads_and_vars)\n    /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/keras/optimizer_v2/utils.py:75 filter_empty_gradients\n        raise ValueError(\"No gradients provided for any variable: %s.\" %\n\n    ValueError: No gradients provided for any variable: ['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0'].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3j/8ntx2dl50txdncnzs2t83lqc0000gn/T/ipykernel_27122/4185119181.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 763\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    764\u001b[0m             *args, **kwds))\n\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3049\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3050\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3051\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3444\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3277\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3278\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3279\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3280\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3281\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    984\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:855 train_function  *\n        return step_function(self, iterator)\n    /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:845 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:838 run_step  **\n        outputs = model.train_step(data)\n    /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:799 train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:530 minimize\n        return self.apply_gradients(grads_and_vars, name=name)\n    /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:630 apply_gradients\n        grads_and_vars = optimizer_utils.filter_empty_gradients(grads_and_vars)\n    /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/keras/optimizer_v2/utils.py:75 filter_empty_gradients\n        raise ValueError(\"No gradients provided for any variable: %s.\" %\n\n    ValueError: No gradients provided for any variable: ['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0'].\n"
     ]
    }
   ],
   "source": [
    "epochs=60\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs,\n",
    "  callbacks=create_callbacks(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              loss=TripletLossFn(0.7),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-27 16:15:20.821114: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Cannot assign a device for operation sequential_1/sequential/random_rotation/stateful_uniform/RngReadAndSkip: Could not satisfy explicit device specification '' because the node {{colocation_node sequential_1/sequential/random_rotation/stateful_uniform/RngReadAndSkip}} was colocated with a group of nodes that required incompatible device '/job:localhost/replica:0/task:0/device:GPU:0'. All available devices [/job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:GPU:0]. \nColocation Debug Info:\nColocation group had the following types and supported devices: \nRoot Member(assigned_device_name_index_=2 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\nRngReadAndSkip: CPU \n_Arg: GPU CPU \n\nColocation members, user-requested devices, and framework assigned devices, if any:\n  sequential_1_sequential_random_rotation_stateful_uniform_rngreadandskip_resource (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0\n  sequential_1/sequential/random_rotation/stateful_uniform/RngReadAndSkip (RngReadAndSkip) \n\n\t [[{{node sequential_1/sequential/random_rotation/stateful_uniform/RngReadAndSkip}}]] [Op:__inference_train_function_2625]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3j/8ntx2dl50txdncnzs2t83lqc0000gn/T/ipykernel_27122/4185119181.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation sequential_1/sequential/random_rotation/stateful_uniform/RngReadAndSkip: Could not satisfy explicit device specification '' because the node {{colocation_node sequential_1/sequential/random_rotation/stateful_uniform/RngReadAndSkip}} was colocated with a group of nodes that required incompatible device '/job:localhost/replica:0/task:0/device:GPU:0'. All available devices [/job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:GPU:0]. \nColocation Debug Info:\nColocation group had the following types and supported devices: \nRoot Member(assigned_device_name_index_=2 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\nRngReadAndSkip: CPU \n_Arg: GPU CPU \n\nColocation members, user-requested devices, and framework assigned devices, if any:\n  sequential_1_sequential_random_rotation_stateful_uniform_rngreadandskip_resource (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0\n  sequential_1/sequential/random_rotation/stateful_uniform/RngReadAndSkip (RngReadAndSkip) \n\n\t [[{{node sequential_1/sequential/random_rotation/stateful_uniform/RngReadAndSkip}}]] [Op:__inference_train_function_2625]"
     ]
    }
   ],
   "source": [
    "epochs=60\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs,\n",
    "  callbacks=create_callbacks(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3j/8ntx2dl50txdncnzs2t83lqc0000gn/T/ipykernel_27122/234510614.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#### acc = history.history['accuracy']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "#### acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(27)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/gabriellevieira/Documents/GitHub/TensorflowLite_Image_Classification_Training/test_images/0006c8e5462ae52167402bac1c2e916e.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3j/8ntx2dl50txdncnzs2t83lqc0000gn/T/ipykernel_27122/3919680088.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/Users/gabriellevieira/Documents/GitHub/TensorflowLite_Image_Classification_Training/test_images/0006c8e5462ae52167402bac1c2e916e.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m img = keras.preprocessing.image.load_img(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtest_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    293\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minterpolation\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msupported\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m   \"\"\"\n\u001b[0;32m--> 295\u001b[0;31m   return image.load_img(path, grayscale=grayscale, color_mode=color_mode,\n\u001b[0m\u001b[1;32m    296\u001b[0m                         target_size=target_size, interpolation=interpolation)\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    111\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    112\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/gabriellevieira/Documents/GitHub/TensorflowLite_Image_Classification_Training/test_images/0006c8e5462ae52167402bac1c2e916e.jpg'"
     ]
    }
   ],
   "source": [
    "test_path = '/Users/gabriellevieira/Documents/GitHub/TensorflowLite_Image_Classification_Training/test_images/0006c8e5462ae52167402bac1c2e916e.jpg'\n",
    "\n",
    "img = keras.preprocessing.image.load_img(\n",
    "    test_path, target_size=(img_height, img_width)\n",
    ")\n",
    "img_array = keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions)\n",
    "\n",
    "data[data['label'] == np.argmax(score)]\n",
    "\n",
    "#print(\n",
    "#    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "#    .format(data[data['label'] == np.argmax(score)]['title'][0], 100 * np.max(score))\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "      <th>label_group</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [posting_id, image, image_phash, title, label_group, label]\n",
       "Index: []"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['image_phash'] == 'ecc292392dc7687a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "in user code:\n\n    /var/folders/3j/8ntx2dl50txdncnzs2t83lqc0000gn/T/ipykernel_27122/1125200220.py:1 None  *\n        lambda x, y: (normalization_layer(x), y)\n\n    NameError: name 'normalization_layer' is not defined\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3j/8ntx2dl50txdncnzs2t83lqc0000gn/T/ipykernel_27122/1125200220.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnormalized_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnormalization_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mimage_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalized_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfirst_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Notice the pixels values are now in `[0,1]`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic)\u001b[0m\n\u001b[1;32m   1923\u001b[0m         warnings.warn(\"The `deterministic` argument has no effect unless the \"\n\u001b[1;32m   1924\u001b[0m                       \"`num_parallel_calls` argument is specified.\")\n\u001b[0;32m-> 1925\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1926\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1927\u001b[0m       return ParallelMapDataset(\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   4481\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_inter_op_parallelism\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_inter_op_parallelism\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4482\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preserve_cardinality\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4483\u001b[0;31m     self._map_func = StructuredFunctionWrapper(\n\u001b[0m\u001b[1;32m   4484\u001b[0m         \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4485\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3710\u001b[0m     \u001b[0mresource_tracker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResourceTracker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3711\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3712\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3713\u001b[0m       \u001b[0;31m# There is no graph to add in eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3714\u001b[0m       \u001b[0madd_to_graph\u001b[0m \u001b[0;34m&=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3132\u001b[0m          \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorSpec\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m     \"\"\"\n\u001b[0;32m-> 3134\u001b[0;31m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0m\u001b[1;32m   3135\u001b[0m         *args, **kwargs)\n\u001b[1;32m   3136\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3098\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3099\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3100\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3101\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3102\u001b[0m       captured = object_identity.ObjectIdentitySet(\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3444\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3277\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3278\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3279\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3280\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3281\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3685\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   3686\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3687\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3688\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3689\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3615\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_should_unpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3616\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3617\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3618\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0m_should_pack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3619\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    693\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    696\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: in user code:\n\n    /var/folders/3j/8ntx2dl50txdncnzs2t83lqc0000gn/T/ipykernel_27122/1125200220.py:1 None  *\n        lambda x, y: (normalization_layer(x), y)\n\n    NameError: name 'normalization_layer' is not defined\n"
     ]
    }
   ],
   "source": [
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[0]\n",
    "# Notice the pixels values are now in `[0,1]`.\n",
    "print(np.min(first_image), np.max(first_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_callbacks():\n",
    "    \n",
    "    cpk_path = './best_model.h5'\n",
    "    \n",
    "    reducelr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        factor=0.1,\n",
    "        patience=3,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=cpk_path,\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        save_best_only=True,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    earlystop = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        patience=10, \n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    callbacks = [checkpoint, reducelr, earlystop]         \n",
    "    \n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPLICAS:  1\n"
     ]
    }
   ],
   "source": [
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  \n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES =  data['label'].nunique()\n",
    "BATCH_SIZE = BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n",
    "HEIGHT,WIDTH = 512,512\n",
    "CHANNELS = 3\n",
    "SPLIT = int(0.8*len(train_ds))\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "STEPS_PER_EPOCH  = SPLIT//BATCH_SIZE\n",
    "VALID_STEPS = (len(train_ds)-SPLIT)//BATCH_SIZE\n",
    "SEED = 143"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'efn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3j/8ntx2dl50txdncnzs2t83lqc0000gn/T/ipykernel_2462/2037805930.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/3j/8ntx2dl50txdncnzs2t83lqc0000gn/T/ipykernel_2462/2037805930.py\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mpretrained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mefn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEfficientNetB7\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'noisy-student'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mHEIGHT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mWIDTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'efn' is not defined"
     ]
    }
   ],
   "source": [
    "class NormalizeLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(NormalizeLayer, self).__init__()\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        return tf.math.l2_normalize(inputs, axis=-1)\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config}\n",
    "    \n",
    "norm_layer = NormalizeLayer()\n",
    "\n",
    "def create_model():\n",
    "    pretrained = efn.EfficientNetB7(include_top=False, weights='noisy-student',input_shape=[HEIGHT,WIDTH, 3])\n",
    "            \n",
    "    x = pretrained.output\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    outputs = norm_layer (x)\n",
    "        \n",
    "    model = tf.keras.Model(pretrained.input, outputs)\n",
    "    return model\n",
    "\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_distances(embeddings):\n",
    "    dot_product = tf.linalg.matmul(embeddings, tf.transpose(embeddings))\n",
    "    square_norm = tf.linalg.diag_part(dot_product)\n",
    "    distances = tf.expand_dims(square_norm, 1) - 2.0 * dot_product + tf.expand_dims(square_norm, 0)\n",
    "    distances = tf.math.maximum(distances, 0.0)\n",
    "\n",
    "    mask = tf.cast(tf.equal(distances, 0.0),tf.float32)\n",
    "    distances = distances + mask * 1e-16\n",
    "    distances = tf.math.sqrt(distances)\n",
    "    distances = distances * (1.0 - mask)\n",
    "\n",
    "    return distances\n",
    "\n",
    "def get_anchor_positive_triplet_mask(labels):\n",
    "    indices_equal = tf.cast(tf.eye(tf.shape(labels)[0]), tf.bool)\n",
    "    indices_not_equal = tf.math.logical_not(indices_equal)\n",
    "\n",
    "    labels_equal = tf.math.equal(tf.expand_dims(labels, 0), tf.expand_dims(labels, 1))\n",
    "    mask = tf.math.logical_and(indices_not_equal, labels_equal)\n",
    "\n",
    "    return mask\n",
    "\n",
    "def get_anchor_negative_triplet_mask(labels):\n",
    "    labels_equal = tf.math.equal(tf.expand_dims(labels, 0), tf.expand_dims(labels, 1))\n",
    "    mask = tf.math.logical_not(labels_equal)\n",
    "\n",
    "    return mask\n",
    "\n",
    "def get_triplet_mask(labels):\n",
    "    indices_equal = tf.cast(tf.eye(tf.shape(labels)[0]), tf.bool)\n",
    "    indices_not_equal = tf.math.logical_not(indices_equal)\n",
    "    i_not_equal_j = tf.expand_dims(indices_not_equal, 2)\n",
    "    i_not_equal_k = tf.expand_dims(indices_not_equal, 1)\n",
    "    j_not_equal_k = tf.expand_dims(indices_not_equal, 0)\n",
    "\n",
    "    distinct_indices = tf.math.logical_and(tf.math.logical_and(i_not_equal_j, i_not_equal_k), j_not_equal_k)\n",
    "\n",
    "\n",
    "    label_equal = tf.math.equal(tf.expand_dims(labels, 0), tf.expand_dims(labels, 1))\n",
    "    i_equal_j = tf.expand_dims(label_equal, 2)\n",
    "    i_equal_k = tf.expand_dims(label_equal, 1)\n",
    "\n",
    "    valid_labels = tf.math.logical_and(i_equal_j, tf.logical_not(i_equal_k))\n",
    "\n",
    "    mask = tf.math.logical_and(distinct_indices, valid_labels)\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "class TripletLossFn(tf.keras.losses.Loss):\n",
    "    def __init__(self,margin=1.0,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.margin = margin\n",
    "  \n",
    "    def call(self,y_true,y_pred):\n",
    "\n",
    "        labels = tf.convert_to_tensor(y_true)\n",
    "        labels = tf.squeeze(labels,axis=-1)\n",
    "        embeddings = tf.convert_to_tensor(y_pred)\n",
    "\n",
    "        pairwise_dist = pairwise_distances(embeddings)\n",
    "\n",
    "        mask_anchor_positive = get_anchor_positive_triplet_mask(labels)\n",
    "        mask_anchor_positive = tf.cast(mask_anchor_positive,tf.float32)\n",
    "\n",
    "        anchor_positive_dist = tf.math.multiply(mask_anchor_positive, pairwise_dist)\n",
    "\n",
    "        hardest_positive_dist = tf.math.reduce_max(anchor_positive_dist, axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "        mask_anchor_negative = get_anchor_negative_triplet_mask(labels)\n",
    "        mask_anchor_negative = tf.cast(mask_anchor_negative,tf.float32)\n",
    "\n",
    "        max_anchor_negative_dist = tf.math.reduce_max(pairwise_dist, axis=1, keepdims=True)\n",
    "        anchor_negative_dist = pairwise_dist + max_anchor_negative_dist * (1.0 - mask_anchor_negative)\n",
    "\n",
    "\n",
    "        hardest_negative_dist = tf.math.reduce_min(anchor_negative_dist, axis=1, keepdims=True)\n",
    "    \n",
    "\n",
    "        triplet_loss = tf.math.maximum(hardest_positive_dist - hardest_negative_dist + self.margin, 0.0)\n",
    "\n",
    "        triplet_loss = tf.math.reduce_mean(triplet_loss)\n",
    "\n",
    "        return triplet_loss\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config,\"margin\":self.margin}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_addons'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3j/8ntx2dl50txdncnzs2t83lqc0000gn/T/ipykernel_2462/367624432.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_addons\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompile_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_addons'"
     ]
    }
   ],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "def compile_model(model, lr=0.0001):\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(lr=lr)\n",
    "    \n",
    "    #loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    loss = TripletLossFn(0.7) \n",
    "    metrics = [\n",
    "       tf.keras.metrics.SparseCategoricalAccuracy(name='acc')\n",
    "    ]\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=loss)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'efn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3j/8ntx2dl50txdncnzs2t83lqc0000gn/T/ipykernel_2462/180280540.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompile_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/3j/8ntx2dl50txdncnzs2t83lqc0000gn/T/ipykernel_2462/2037805930.py\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mpretrained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mefn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEfficientNetB7\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'noisy-student'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mHEIGHT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mWIDTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'efn' is not defined"
     ]
    }
   ],
   "source": [
    "EPOCHS= 50\n",
    "VERBOSE =1\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "with strategy.scope():\n",
    "    \n",
    "    model = create_model()\n",
    "    model = compile_model(model, lr=0.0001)\n",
    "   \n",
    "    callbacks = create_callbacks()\n",
    "    \n",
    "    history = model.fit(train_ds, \n",
    "                        epochs=EPOCHS,\n",
    "                        callbacks=callbacks,\n",
    "                        validation_data = val_ds,\n",
    "                        verbose=VERBOSE,\n",
    "                        steps_per_epoch = STEPS_PER_EPOCH,\n",
    "                        validation_steps=VALID_STEPS\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPLICAS:  1\n"
     ]
    }
   ],
   "source": [
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  \n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/gabriellevieira/Documents/GitHub/TensorflowLite_Image_Classification_Training/train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3j/8ntx2dl50txdncnzs2t83lqc0000gn/T/ipykernel_2462/3741405013.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/gabriellevieira/Documents/GitHub/TensorflowLite_Image_Classification_Training/train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlabel2id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_group\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnunique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_group\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mid2label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_group\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_group\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnunique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label_group\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label_group\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid2label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/gabriellevieira/Documents/GitHub/TensorflowLite_Image_Classification_Training/train.csv'"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('/Users/gabriellevieira/Documents/GitHub/TensorflowLite_Image_Classification_Training/train.csv')\n",
    "\n",
    "label2id = dict(zip(range(train_df.label_group.nunique()),train_df.label_group.unique()))\n",
    "id2label = dict(zip(train_df.label_group.unique(),range(train_df.label_group.nunique())))\n",
    "train_df[\"label_group\"] = train_df[\"label_group\"].map(id2label)\n",
    "train_df.index = train_df[\"image\"]\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3j/8ntx2dl50txdncnzs2t83lqc0000gn/T/ipykernel_2462/1760259590.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"posting_label\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'label_group'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposting_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unique'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'posting_ids'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_group\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'posting_ids'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'posting_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "train_df[\"posting_label\"] = np.arange(len(train_df))\n",
    "tmp = train_df.groupby('label_group').posting_id.agg('unique').to_dict()\n",
    "train_df['posting_ids'] = train_df.label_group.map(tmp)\n",
    "train_df['posting_ids'] = train_df['posting_ids'].apply(lambda x: list(x))\n",
    "\n",
    "tmp = train_df.groupby('label_group').posting_label.agg('unique').to_dict()\n",
    "train_df['posting_labels'] = train_df.label_group.map(tmp)\n",
    "train_df['posting_labels'] = train_df['posting_labels'].apply(lambda x: list(x))\n",
    "train_df = train_df.drop_duplicates(subset=['image'])\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3j/8ntx2dl50txdncnzs2t83lqc0000gn/T/ipykernel_2462/1785462032.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mNUM_CLASSES\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label_group'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnunique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_replicas_in_sync\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mHEIGHT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mWIDTH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mCHANNELS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mSPLIT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES =  train_df['label_group'].nunique()\n",
    "BATCH_SIZE = BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n",
    "HEIGHT,WIDTH = 512,512\n",
    "CHANNELS = 3\n",
    "SPLIT = int(0.8*len(train_df))\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "STEPS_PER_EPOCH  = SPLIT//BATCH_SIZE\n",
    "VALID_STEPS = (len(train_df)-SPLIT)//BATCH_SIZE\n",
    "SEED = 143"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3j/8ntx2dl50txdncnzs2t83lqc0000gn/T/ipykernel_2462/1002214986.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"posting_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfilepath_to_arr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mHEIGHT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mWIDTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "train_df.index = train_df[\"posting_id\"]\n",
    "\n",
    "def filepath_to_arr(filepath):\n",
    "    img = tf.keras.preprocessing.image.load_img(filepath,target_size= (HEIGHT,WIDTH))\n",
    "    arr = tf.keras.preprocessing.image.img_to_array(img)/255.\n",
    "    return arr\n",
    "\n",
    "def display_img(training_ids):\n",
    "    num_imgs = len(training_ids)\n",
    " \n",
    "    plt.figure(figsize = (5*num_imgs,10))\n",
    "    for i,_id in enumerate(training_ids):\n",
    "        plt.subplot(1,num_imgs+1,i+1)\n",
    "        \n",
    "        filepath = os.path.join(\"/Users/gabriellevieira/Documents/GitHub/TensorflowLite_Image_Classification_Training/shopee-product-matching/train_images/\",train_df.loc[_id][\"image\"])\n",
    "        plt.title(\"Image : \"+str(i+1))\n",
    "        arr = filepath_to_arr(filepath)\n",
    "        plt.imshow(arr)\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "for j in range(5):\n",
    "    display_img(train_df.iloc[j][\"posting_ids\"])\n",
    "    \n",
    "\n",
    "train_df.index = train_df[\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------\n",
    "##processing image\n",
    "#------------------\n",
    "def process_img(filepath,label):\n",
    "    image = tf.io.read_file(filepath)\n",
    "    image = tf.image.decode_jpeg(image, channels=CHANNELS)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32) \n",
    "    image = tf.image.resize(image, [HEIGHT,WIDTH])\n",
    "    return image,label\n",
    "\n",
    "\n",
    "#-----------------------------------\n",
    "##adding augmentations to image data\n",
    "#-----------------------------------\n",
    "def data_augment(image, label):\n",
    "    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_pixel_1 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_pixel_2 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_pixel_3 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "            \n",
    "    # Flips\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    if p_spatial > .75:\n",
    "        image = tf.image.transpose(image)\n",
    "        \n",
    "    # Rotates\n",
    "    if p_rotate > .75:\n",
    "        image = tf.image.rot90(image, k=3) \n",
    "    elif p_rotate > .5:\n",
    "        image = tf.image.rot90(image, k=2) \n",
    "    elif p_rotate > .25:\n",
    "        image = tf.image.rot90(image, k=1) \n",
    "        \n",
    "    \n",
    "    if p_pixel_1 >= .4:\n",
    "        image = tf.image.random_saturation(image, lower=.7, upper=1.3)\n",
    "    if p_pixel_2 >= .4:\n",
    "        image = tf.image.random_contrast(image, lower=.8, upper=1.2)\n",
    "    if p_pixel_3 >= .4:\n",
    "        image = tf.image.random_brightness(image, max_delta=.1)\n",
    "        \n",
    "    \n",
    "    if p_crop > .7:\n",
    "        if p_crop > .9:\n",
    "            image = tf.image.central_crop(image, central_fraction=.7)\n",
    "        elif p_crop > .8:\n",
    "            image = tf.image.central_crop(image, central_fraction=.8)\n",
    "        else:\n",
    "            image = tf.image.central_crop(image, central_fraction=.9)\n",
    "    elif p_crop > .4:\n",
    "        crop_size = tf.random.uniform([], int(HEIGHT*.8), HEIGHT, dtype=tf.int32)\n",
    "        image = tf.image.random_crop(image, size=[crop_size, crop_size, CHANNELS])\n",
    "    \n",
    "    image = tf.image.resize(image, [HEIGHT,WIDTH])\n",
    "    return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    /var/folders/3j/8ntx2dl50txdncnzs2t83lqc0000gn/T/ipykernel_2462/3046332839.py:5 process_img  *\n        image = tf.io.read_file(filepath)\n    /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/ops/io_ops.py:138 read_file  **\n        return gen_io_ops.read_file(filename, name)\n    /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/ops/gen_io_ops.py:560 read_file\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py:544 _apply_op_helper\n        raise TypeError(\"%s expected type of %s.\" %\n\n    TypeError: Input 'filename' of 'ReadFile' Op has type float32 that does not match expected type of string.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3j/8ntx2dl50txdncnzs2t83lqc0000gn/T/ipykernel_2462/2006692128.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles_ls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_img\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAUTO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_augment\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAUTO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic)\u001b[0m\n\u001b[1;32m   1925\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1926\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1927\u001b[0;31m       return ParallelMapDataset(\n\u001b[0m\u001b[1;32m   1928\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1929\u001b[0m           \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   4520\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4521\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_inter_op_parallelism\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_inter_op_parallelism\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4522\u001b[0;31m     self._map_func = StructuredFunctionWrapper(\n\u001b[0m\u001b[1;32m   4523\u001b[0m         \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4524\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3710\u001b[0m     \u001b[0mresource_tracker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResourceTracker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3711\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3712\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3713\u001b[0m       \u001b[0;31m# There is no graph to add in eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3714\u001b[0m       \u001b[0madd_to_graph\u001b[0m \u001b[0;34m&=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3132\u001b[0m          \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorSpec\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m     \"\"\"\n\u001b[0;32m-> 3134\u001b[0;31m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0m\u001b[1;32m   3135\u001b[0m         *args, **kwargs)\n\u001b[1;32m   3136\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3098\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3099\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3100\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3101\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3102\u001b[0m       captured = object_identity.ObjectIdentitySet(\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3444\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3277\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3278\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3279\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3280\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3281\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3685\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   3686\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3687\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3688\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3689\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3615\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_should_unpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3616\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3617\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3618\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0m_should_pack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3619\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    693\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    696\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    /var/folders/3j/8ntx2dl50txdncnzs2t83lqc0000gn/T/ipykernel_2462/3046332839.py:5 process_img  *\n        image = tf.io.read_file(filepath)\n    /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/ops/io_ops.py:138 read_file  **\n        return gen_io_ops.read_file(filename, name)\n    /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/ops/gen_io_ops.py:560 read_file\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py:544 _apply_op_helper\n        raise TypeError(\"%s expected type of %s.\" %\n\n    TypeError: Input 'filename' of 'ReadFile' Op has type float32 that does not match expected type of string.\n"
     ]
    }
   ],
   "source": [
    "#------------------------\n",
    "##preparing data pipeline\n",
    "#------------------------\n",
    "\n",
    "TRAIN_PATH = '/Users/gabriellevieira/Documents/GitHub/TensorflowLite_Image_Classification_Training/shopee-product-matching/train_images/'\n",
    "\n",
    "files_ls = tf.io.gfile.glob(TRAIN_PATH + '*.jpg')\n",
    "#labels = np.array(train_df.label_group)\n",
    "labels = np.zeros((len(files_ls),))\n",
    "\n",
    "for i,file in enumerate(files_ls):\n",
    "    file = file.split(\"/\")[-1]\n",
    "    labels[i] = train_df.loc[file][\"label_group\"]\n",
    "    #tf.one_hot(train_df.loc[file][\"label_group\"] ,depth = NUM_CLASSES, dtype = tf.int32)\n",
    "    \n",
    "    \n",
    "dataset = tf.data.Dataset.from_tensor_slices((files_ls,labels))\n",
    "dataset = dataset.map(process_img,num_parallel_calls=AUTO)\n",
    "ds = dataset.map(data_augment,num_parallel_calls=AUTO)\n",
    "\n",
    "train_ds = ds.take(SPLIT)\n",
    "val_ds = ds.skip(SPLIT)\n",
    "\n",
    "train_ds = train_ds.cache().repeat().shuffle(2048).batch(BATCH_SIZE).prefetch(AUTO)\n",
    "val_ds = val_ds.cache().repeat().batch(BATCH_SIZE).prefetch(AUTO)\n",
    "print(\"Data Pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'efn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3j/8ntx2dl50txdncnzs2t83lqc0000gn/T/ipykernel_2462/1232475217.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;31m#model.summary()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/3j/8ntx2dl50txdncnzs2t83lqc0000gn/T/ipykernel_2462/1232475217.py\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mpretrained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mefn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEfficientNetB7\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'noisy-student'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mHEIGHT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mWIDTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'efn' is not defined"
     ]
    }
   ],
   "source": [
    "class NormalizeLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(NormalizeLayer, self).__init__()\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        return tf.math.l2_normalize(inputs, axis=-1)\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config}\n",
    "    \n",
    "norm_layer = NormalizeLayer()\n",
    "\n",
    "def create_model():\n",
    "    pretrained = efn.EfficientNetB7(include_top=False, weights='noisy-student',input_shape=[HEIGHT,WIDTH, 3])\n",
    "            \n",
    "    x = pretrained.output\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    outputs = norm_layer (x)\n",
    "        \n",
    "    model = tf.keras.Model(pretrained.input, outputs)\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "#Custom Triplet Loss\n",
    "############\n",
    "\n",
    "def pairwise_distances(embeddings):\n",
    "    dot_product = tf.linalg.matmul(embeddings, tf.transpose(embeddings))\n",
    "    square_norm = tf.linalg.diag_part(dot_product)\n",
    "    distances = tf.expand_dims(square_norm, 1) - 2.0 * dot_product + tf.expand_dims(square_norm, 0)\n",
    "    distances = tf.math.maximum(distances, 0.0)\n",
    "\n",
    "    mask = tf.cast(tf.equal(distances, 0.0),tf.float32)\n",
    "    distances = distances + mask * 1e-16\n",
    "    distances = tf.math.sqrt(distances)\n",
    "    distances = distances * (1.0 - mask)\n",
    "\n",
    "    return distances\n",
    "\n",
    "def get_anchor_positive_triplet_mask(labels):\n",
    "    indices_equal = tf.cast(tf.eye(tf.shape(labels)[0]), tf.bool)\n",
    "    indices_not_equal = tf.math.logical_not(indices_equal)\n",
    "\n",
    "    labels_equal = tf.math.equal(tf.expand_dims(labels, 0), tf.expand_dims(labels, 1))\n",
    "    mask = tf.math.logical_and(indices_not_equal, labels_equal)\n",
    "\n",
    "    return mask\n",
    "\n",
    "def get_anchor_negative_triplet_mask(labels):\n",
    "    labels_equal = tf.math.equal(tf.expand_dims(labels, 0), tf.expand_dims(labels, 1))\n",
    "    mask = tf.math.logical_not(labels_equal)\n",
    "\n",
    "    return mask\n",
    "\n",
    "def get_triplet_mask(labels):\n",
    "    indices_equal = tf.cast(tf.eye(tf.shape(labels)[0]), tf.bool)\n",
    "    indices_not_equal = tf.math.logical_not(indices_equal)\n",
    "    i_not_equal_j = tf.expand_dims(indices_not_equal, 2)\n",
    "    i_not_equal_k = tf.expand_dims(indices_not_equal, 1)\n",
    "    j_not_equal_k = tf.expand_dims(indices_not_equal, 0)\n",
    "\n",
    "    distinct_indices = tf.math.logical_and(tf.math.logical_and(i_not_equal_j, i_not_equal_k), j_not_equal_k)\n",
    "\n",
    "\n",
    "    label_equal = tf.math.equal(tf.expand_dims(labels, 0), tf.expand_dims(labels, 1))\n",
    "    i_equal_j = tf.expand_dims(label_equal, 2)\n",
    "    i_equal_k = tf.expand_dims(label_equal, 1)\n",
    "\n",
    "    valid_labels = tf.math.logical_and(i_equal_j, tf.logical_not(i_equal_k))\n",
    "\n",
    "    mask = tf.math.logical_and(distinct_indices, valid_labels)\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "class TripletLossFn(tf.keras.losses.Loss):\n",
    "    def __init__(self,margin=1.0,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.margin = margin\n",
    "  \n",
    "    def call(self,y_true,y_pred):\n",
    "\n",
    "        labels = tf.convert_to_tensor(y_true)\n",
    "        labels = tf.squeeze(labels,axis=-1)\n",
    "        embeddings = tf.convert_to_tensor(y_pred)\n",
    "\n",
    "        pairwise_dist = pairwise_distances(embeddings)\n",
    "\n",
    "        mask_anchor_positive = get_anchor_positive_triplet_mask(labels)\n",
    "        mask_anchor_positive = tf.cast(mask_anchor_positive,tf.float32)\n",
    "\n",
    "        anchor_positive_dist = tf.math.multiply(mask_anchor_positive, pairwise_dist)\n",
    "\n",
    "        hardest_positive_dist = tf.math.reduce_max(anchor_positive_dist, axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "        mask_anchor_negative = get_anchor_negative_triplet_mask(labels)\n",
    "        mask_anchor_negative = tf.cast(mask_anchor_negative,tf.float32)\n",
    "\n",
    "        max_anchor_negative_dist = tf.math.reduce_max(pairwise_dist, axis=1, keepdims=True)\n",
    "        anchor_negative_dist = pairwise_dist + max_anchor_negative_dist * (1.0 - mask_anchor_negative)\n",
    "\n",
    "\n",
    "        hardest_negative_dist = tf.math.reduce_min(anchor_negative_dist, axis=1, keepdims=True)\n",
    "    \n",
    "\n",
    "        triplet_loss = tf.math.maximum(hardest_positive_dist - hardest_negative_dist + self.margin, 0.0)\n",
    "\n",
    "        triplet_loss = tf.math.reduce_mean(triplet_loss)\n",
    "\n",
    "        return triplet_loss\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config,\"margin\":self.margin}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_addons'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3j/8ntx2dl50txdncnzs2t83lqc0000gn/T/ipykernel_2462/367624432.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_addons\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompile_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_addons'"
     ]
    }
   ],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "def compile_model(model, lr=0.0001):\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(lr=lr)\n",
    "    \n",
    "    #loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    loss = TripletLossFn(0.7) \n",
    "    metrics = [\n",
    "       tf.keras.metrics.SparseCategoricalAccuracy(name='acc')\n",
    "    ]\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=loss)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_callbacks():\n",
    "    \n",
    "    cpk_path = './best_model.h5'\n",
    "    \n",
    "    reducelr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        factor=0.1,\n",
    "        patience=3,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=cpk_path,\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        save_best_only=True,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    earlystop = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        patience=10, \n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    callbacks = [checkpoint, reducelr, earlystop]         \n",
    "    \n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'efn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3j/8ntx2dl50txdncnzs2t83lqc0000gn/T/ipykernel_2462/180280540.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompile_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/3j/8ntx2dl50txdncnzs2t83lqc0000gn/T/ipykernel_2462/1232475217.py\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mpretrained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mefn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEfficientNetB7\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'noisy-student'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mHEIGHT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mWIDTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'efn' is not defined"
     ]
    }
   ],
   "source": [
    "EPOCHS= 50\n",
    "VERBOSE =1\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "with strategy.scope():\n",
    "    \n",
    "    model = create_model()\n",
    "    model = compile_model(model, lr=0.0001)\n",
    "   \n",
    "    callbacks = create_callbacks()\n",
    "    \n",
    "    history = model.fit(train_ds, \n",
    "                        epochs=EPOCHS,\n",
    "                        callbacks=callbacks,\n",
    "                        validation_data = val_ds,\n",
    "                        verbose=VERBOSE,\n",
    "                        steps_per_epoch = STEPS_PER_EPOCH,\n",
    "                        validation_steps=VALID_STEPS\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow (from keras-toolkit) (from versions: none)\u001b[0m\r\n",
      "\u001b[31mERROR: No matching distribution found for tensorflow\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-toolkit==0.1.0rc6 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras_toolkit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3j/8ntx2dl50txdncnzs2t83lqc0000gn/T/ipykernel_2462/52700352.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_toolkit\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mkt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras_toolkit'"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.applications import resnet\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras_toolkit as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_shape = (200, 200)\n",
    "def preprocess_image(filename, target_shape=target_shape):\n",
    "    \"\"\"\n",
    "    Load the specified file as a JPEG image, preprocess it and\n",
    "    resize it to the target shape.\n",
    "    \"\"\"\n",
    "\n",
    "    img_str = tf.io.read_file(filename)\n",
    "    img = tf.image.decode_jpeg(img_str, channels=3)\n",
    "    img = tf.image.resize(img, target_shape)\n",
    "    \n",
    "    # Resnet-style preprocessing, see: https://git.io/JYo77\n",
    "    mean = [103.939, 116.779, 123.68]\n",
    "    img = img[..., ::-1]\n",
    "    img -= mean\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def build_triplets_dset(df, bsize=32, cache=True, shuffle=False):\n",
    "    \"\"\"\n",
    "    Given the filenames corresponding to the three images, load and\n",
    "    preprocess them.\n",
    "    \"\"\"\n",
    "    \n",
    "    build_dataset = partial(\n",
    "        kt.image.build_dataset,\n",
    "        decode_fn=preprocess_image,\n",
    "        bsize=bsize,\n",
    "        cache=cache,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    danchor = build_dataset(df.anchor)\n",
    "    dpositive = build_dataset(df.positive)\n",
    "    dnegative = build_dataset(df.negative)\n",
    "\n",
    "    dset = tf.data.Dtaset.zip((danchor, dpositive, dnegative))\n",
    "    \n",
    "    if shuffle:\n",
    "        dset = dset.shuffle(shuffle)\n",
    "    \n",
    "    return dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaggle\n",
    "\n",
    "kaggle.api.authenticate()\n",
    "\n",
    "kaggle.api.dataset_download_files('shopee-product-matching', path='shopee-training-images-200px-jpg', unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (859330756.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/3j/8ntx2dl50txdncnzs2t83lqc0000gn/T/ipykernel_2462/859330756.py\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    GCS_DS_PATH =\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "COMPETITION_NAME = 'shopee-product-matching'\n",
    "strategy = kt.accelerator.auto_select(verbose=True)\n",
    "GCS_DS_PATH = \n",
    "BATCH_SIZE = strategy.num_replicas_in_sync * 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/gabriellevieira/Documents/GitHub/TensorflowLite_Image_Classification_Training/train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3j/8ntx2dl50txdncnzs2t83lqc0000gn/T/ipykernel_2462/322427847.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/gabriellevieira/Documents/GitHub/TensorflowLite_Image_Classification_Training/train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mGCS_DS_PATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_paths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/gabriellevieira/Documents/GitHub/TensorflowLite_Image_Classification_Training/train.csv'"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('/Users/gabriellevieira/Documents/GitHub/TensorflowLite_Image_Classification_Training/train.csv')\n",
    "\n",
    "train = train.apply(lambda col: GCS_DS_PATH + '/' + col)\n",
    "train_paths, val_paths = train_test_split(train, train_size=0.8, random_state=42)\n",
    "train_paths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'build_triplets_dset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3j/8ntx2dl50txdncnzs2t83lqc0000gn/T/ipykernel_2462/2859699235.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m dtrain = build_triplets_dset(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_paths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mbsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8192\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'build_triplets_dset' is not defined"
     ]
    }
   ],
   "source": [
    "dtrain = build_triplets_dset(\n",
    "    train_paths,\n",
    "    bsize=BATCH_SIZE,\n",
    "    cache=True,\n",
    "    shuffle=8192\n",
    ")\n",
    "\n",
    "dvalid = build_triplets_dset(\n",
    "    val_paths,\n",
    "    bsize=BATCH_SIZE,\n",
    "    cache=True,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.applications import resnet\n",
    "\n",
    "\n",
    "target_shape = (200, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = Path(Path.home()) / \".keras\"\n",
    "anchor_images_path = cache_dir / \"left\"\n",
    "positive_images_path = cache_dir / \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: gdown\n",
      "zsh:1: command not found: gdown\n",
      "unzip:  cannot find or open left.zip, left.zip.zip or left.zip.ZIP.\n",
      "unzip:  cannot find or open right.zip, right.zip.zip or right.zip.ZIP.\n"
     ]
    }
   ],
   "source": [
    "!gdown --id 1jvkbTr_giSP3Ru8OwGNCg6B4PvVbcO34\n",
    "!gdown --id 1EzBZUb_mh_Dp_FKD0P4XiYYSd0QBH5zW\n",
    "!unzip -oq left.zip -d $cache_dir\n",
    "!unzip -oq right.zip -d $cache_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(filename):\n",
    "    \"\"\"\n",
    "    Load the specified file as a JPEG image, preprocess it and\n",
    "    resize it to the target shape.\n",
    "    \"\"\"\n",
    "\n",
    "    image_string = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_jpeg(image_string, channels=3)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, target_shape)\n",
    "    return image\n",
    "\n",
    "\n",
    "def preprocess_triplets(anchor, positive, negative):\n",
    "    \"\"\"\n",
    "    Given the filenames corresponding to the three images, load and\n",
    "    preprocess them.\n",
    "    \"\"\"\n",
    "\n",
    "    return (\n",
    "        preprocess_image(anchor),\n",
    "        preprocess_image(positive),\n",
    "        preprocess_image(negative),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/robsonfeliciano/.keras/left'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3j/8ntx2dl50txdncnzs2t83lqc0000gn/T/ipykernel_27122/2540750554.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# sorted order so we can match them together.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m anchor_images = sorted(\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manchor_images_path\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manchor_images_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/robsonfeliciano/.keras/left'"
     ]
    }
   ],
   "source": [
    "# We need to make sure both the anchor and positive images are loaded in\n",
    "# sorted order so we can match them together.\n",
    "anchor_images = sorted(\n",
    "    [str(anchor_images_path / f) for f in os.listdir(anchor_images_path)]\n",
    ")\n",
    "\n",
    "positive_images = sorted(\n",
    "    [str(positive_images_path / f) for f in os.listdir(positive_images_path)]\n",
    ")\n",
    "\n",
    "image_count = len(anchor_images)\n",
    "\n",
    "anchor_dataset = tf.data.Dataset.from_tensor_slices(anchor_images)\n",
    "positive_dataset = tf.data.Dataset.from_tensor_slices(positive_images)\n",
    "\n",
    "# To generate the list of negative images, let's randomize the list of\n",
    "# available images and concatenate them together.\n",
    "rng = np.random.RandomState(seed=42)\n",
    "rng.shuffle(anchor_images)\n",
    "rng.shuffle(positive_images)\n",
    "\n",
    "negative_images = anchor_images + positive_images\n",
    "np.random.RandomState(seed=32).shuffle(negative_images)\n",
    "\n",
    "negative_dataset = tf.data.Dataset.from_tensor_slices(negative_images)\n",
    "negative_dataset = negative_dataset.shuffle(buffer_size=4096)\n",
    "\n",
    "dataset = tf.data.Dataset.zip((anchor_dataset, positive_dataset, negative_dataset))\n",
    "dataset = dataset.shuffle(buffer_size=1024)\n",
    "dataset = dataset.map(preprocess_triplets)\n",
    "\n",
    "# Let's now split our dataset in train and validation.\n",
    "train_dataset = dataset.take(round(image_count * 0.8))\n",
    "val_dataset = dataset.skip(round(image_count * 0.8))\n",
    "\n",
    "train_dataset = train_dataset.batch(32, drop_remainder=False)\n",
    "train_dataset = train_dataset.prefetch(8)\n",
    "\n",
    "val_dataset = val_dataset.batch(32, drop_remainder=False)\n",
    "val_dataset = val_dataset.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_cnn = resnet.ResNet50(\n",
    "    weights=\"imagenet\", input_shape=target_shape + (3,), include_top=False\n",
    ")\n",
    "\n",
    "flatten = layers.Flatten()(base_cnn.output)\n",
    "dense1 = layers.Dense(512, activation=\"relu\")(flatten)\n",
    "dense1 = layers.BatchNormalization()(dense1)\n",
    "dense2 = layers.Dense(256, activation=\"relu\")(dense1)\n",
    "dense2 = layers.BatchNormalization()(dense2)\n",
    "output = layers.Dense(256)(dense2)\n",
    "\n",
    "embedding = Model(base_cnn.input, output, name=\"Embedding\")\n",
    "\n",
    "trainable = False\n",
    "for layer in base_cnn.layers:\n",
    "    if layer.name == \"conv5_block1_out\":\n",
    "        trainable = True\n",
    "    layer.trainable = trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistanceLayer(layers.Layer):\n",
    "    \"\"\"\n",
    "    This layer is responsible for computing the distance between the anchor\n",
    "    embedding and the positive embedding, and the anchor embedding and the\n",
    "    negative embedding.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, anchor, positive, negative):\n",
    "        ap_distance = tf.reduce_sum(tf.square(anchor - positive), -1)\n",
    "        an_distance = tf.reduce_sum(tf.square(anchor - negative), -1)\n",
    "        return (ap_distance, an_distance)\n",
    "\n",
    "\n",
    "anchor_input = layers.Input(name=\"anchor\", shape=target_shape + (3,))\n",
    "positive_input = layers.Input(name=\"positive\", shape=target_shape + (3,))\n",
    "negative_input = layers.Input(name=\"negative\", shape=target_shape + (3,))\n",
    "\n",
    "distances = DistanceLayer()(\n",
    "    embedding(resnet.preprocess_input(anchor_input)),\n",
    "    embedding(resnet.preprocess_input(positive_input)),\n",
    "    embedding(resnet.preprocess_input(negative_input)),\n",
    ")\n",
    "\n",
    "siamese_network = Model(\n",
    "    inputs=[anchor_input, positive_input, negative_input], outputs=distances\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseModel(Model):\n",
    "    \"\"\"The Siamese Network model with a custom training and testing loops.\n",
    "\n",
    "    Computes the triplet loss using the three embeddings produced by the\n",
    "    Siamese Network.\n",
    "\n",
    "    The triplet loss is defined as:\n",
    "       L(A, P, N) = max(â€–f(A) - f(P)â€–Â² - â€–f(A) - f(N)â€–Â² + margin, 0)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, siamese_network, margin=0.5):\n",
    "        super(SiameseModel, self).__init__()\n",
    "        self.siamese_network = siamese_network\n",
    "        self.margin = margin\n",
    "        self.loss_tracker = metrics.Mean(name=\"loss\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.siamese_network(inputs)\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # GradientTape is a context manager that records every operation that\n",
    "        # you do inside. We are using it here to compute the loss so we can get\n",
    "        # the gradients and apply them using the optimizer specified in\n",
    "        # `compile()`.\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = self._compute_loss(data)\n",
    "\n",
    "        # Storing the gradients of the loss function with respect to the\n",
    "        # weights/parameters.\n",
    "        gradients = tape.gradient(loss, self.siamese_network.trainable_weights)\n",
    "\n",
    "        # Applying the gradients on the model using the specified optimizer\n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(gradients, self.siamese_network.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Let's update and return the training loss metric.\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {\"loss\": self.loss_tracker.result()}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        loss = self._compute_loss(data)\n",
    "\n",
    "        # Let's update and return the loss metric.\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {\"loss\": self.loss_tracker.result()}\n",
    "\n",
    "    def _compute_loss(self, data):\n",
    "        # The output of the network is a tuple containing the distances\n",
    "        # between the anchor and the positive example, and the anchor and\n",
    "        # the negative example.\n",
    "        ap_distance, an_distance = self.siamese_network(data)\n",
    "\n",
    "        # Computing the Triplet Loss by subtracting both distances and\n",
    "        # making sure we don't get a negative value.\n",
    "        loss = ap_distance - an_distance\n",
    "        loss = tf.maximum(loss + self.margin, 0.0)\n",
    "        return loss\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        # We need to list our metrics here so the `reset_states()` can be\n",
    "        # called automatically.\n",
    "        return [self.loss_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:855 train_function  *\n        return step_function(self, iterator)\n    /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:845 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:838 run_step  **\n        outputs = model.train_step(data)\n    /var/folders/3j/8ntx2dl50txdncnzs2t83lqc0000gn/T/ipykernel_27122/2555165863.py:26 train_step\n        loss = self._compute_loss(data)\n    /var/folders/3j/8ntx2dl50txdncnzs2t83lqc0000gn/T/ipykernel_27122/2555165863.py:52 _compute_loss\n        ap_distance, an_distance = self.siamese_network(data)\n    /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:1013 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/keras/engine/input_spec.py:200 assert_input_compatibility\n        raise ValueError('Layer ' + layer_name + ' expects ' +\n\n    ValueError: Layer model expects 3 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 200, 200, 3) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3j/8ntx2dl50txdncnzs2t83lqc0000gn/T/ipykernel_27122/3886447285.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msiamese_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSiameseModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msiamese_network\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msiamese_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msiamese_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 763\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    764\u001b[0m             *args, **kwds))\n\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3049\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3050\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3051\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3444\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3277\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3278\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3279\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3280\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3281\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    984\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:855 train_function  *\n        return step_function(self, iterator)\n    /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:845 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:838 run_step  **\n        outputs = model.train_step(data)\n    /var/folders/3j/8ntx2dl50txdncnzs2t83lqc0000gn/T/ipykernel_27122/2555165863.py:26 train_step\n        loss = self._compute_loss(data)\n    /var/folders/3j/8ntx2dl50txdncnzs2t83lqc0000gn/T/ipykernel_27122/2555165863.py:52 _compute_loss\n        ap_distance, an_distance = self.siamese_network(data)\n    /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:1013 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/keras/engine/input_spec.py:200 assert_input_compatibility\n        raise ValueError('Layer ' + layer_name + ' expects ' +\n\n    ValueError: Layer model expects 3 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 200, 200, 3) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "siamese_model = SiameseModel(siamese_network)\n",
    "siamese_model.compile(optimizer=optimizers.Adam(0.0001))\n",
    "siamese_model.fit(train_ds, epochs=50, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
